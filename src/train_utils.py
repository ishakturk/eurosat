"""
EuroSAT EÄŸitim ve DeÄŸerlendirme YardÄ±mcÄ± FonksiyonlarÄ±
======================================================
Bu modÃ¼l eÄŸitim dÃ¶ngÃ¼sÃ¼, deÄŸerlendirme metrikleri ve gÃ¶rselleÅŸtirme fonksiyonlarÄ±nÄ± iÃ§erir.
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    confusion_matrix,
    classification_report,
    precision_recall_fscore_support,
    accuracy_score,
    roc_curve,
    auc
)
from tqdm import tqdm
import time
import os


# ==================== EÄžÄ°TÄ°M FONKSÄ°YONLARI ====================
def train_one_epoch(model, dataloader, criterion, optimizer, device):
    """
    Bir epoch eÄŸitim yapar.

    Args:
        model: EÄŸitilecek model
        dataloader: EÄŸitim DataLoader
        criterion: Loss fonksiyonu
        optimizer: Optimizer
        device: Cihaz (cuda/cpu)

    Returns:
        tuple: (epoch_loss, epoch_accuracy)
    """
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    pbar = tqdm(dataloader, desc="Training", leave=False)
    for images, labels in pbar:
        images, labels = images.to(device), labels.to(device)

        # Forward pass
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward pass
        loss.backward()
        optimizer.step()

        # Ä°statistikler
        running_loss += loss.item() * images.size(0)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        # Progress bar gÃ¼ncelle
        pbar.set_postfix({
            'loss': f'{loss.item():.4f}',
            'acc': f'{100*correct/total:.2f}%'
        })

    epoch_loss = running_loss / total
    epoch_acc = correct / total

    return epoch_loss, epoch_acc


def validate(model, dataloader, criterion, device):
    """
    Model validasyonu yapar.

    Args:
        model: DeÄŸerlendirilecek model
        dataloader: Validation/Test DataLoader
        criterion: Loss fonksiyonu
        device: Cihaz (cuda/cpu)

    Returns:
        tuple: (val_loss, val_accuracy, all_preds, all_labels)
    """
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    all_preds = []
    all_labels = []
    all_probs = []

    with torch.no_grad():
        pbar = tqdm(dataloader, desc="Validating", leave=False)
        for images, labels in pbar:
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            running_loss += loss.item() * images.size(0)

            probs = torch.softmax(outputs, dim=1)
            _, predicted = torch.max(outputs.data, 1)

            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())

    val_loss = running_loss / total
    val_acc = correct / total

    return val_loss, val_acc, np.array(all_preds), np.array(all_labels), np.array(all_probs)


# ==================== TAM EÄžÄ°TÄ°M DÃ–NGÃœSÃœ ====================
def train_model(model, train_loader, val_loader, criterion, optimizer,
                scheduler=None, num_epochs=10, device='cuda',
                save_path='./models/best_model.pth', early_stopping_patience=5):
    """
    Tam eÄŸitim dÃ¶ngÃ¼sÃ¼.

    Args:
        model: EÄŸitilecek model
        train_loader: EÄŸitim DataLoader
        val_loader: Validation DataLoader
        criterion: Loss fonksiyonu
        optimizer: Optimizer
        scheduler: Learning rate scheduler (opsiyonel)
        num_epochs: Epoch sayÄ±sÄ±
        device: Cihaz (cuda/cpu)
        save_path: En iyi model kayÄ±t yolu
        early_stopping_patience: Early stopping iÃ§in sabÄ±r deÄŸeri

    Returns:
        dict: EÄŸitim geÃ§miÅŸi (history)
    """
    # GeÃ§miÅŸ kayÄ±t
    history = {
        'train_loss': [],
        'train_acc': [],
        'val_loss': [],
        'val_acc': [],
        'lr': []
    }

    best_val_acc = 0.0
    patience_counter = 0
    start_time = time.time()

    print("\n" + "="*60)
    print("ðŸš€ EÄžÄ°TÄ°M BAÅžLIYOR")
    print("="*60)
    print(f"Cihaz: {device}")
    print(f"Epoch sayÄ±sÄ±: {num_epochs}")
    print(f"Early stopping patience: {early_stopping_patience}")
    print("="*60 + "\n")

    for epoch in range(num_epochs):
        epoch_start = time.time()

        # EÄŸitim
        train_loss, train_acc = train_one_epoch(
            model, train_loader, criterion, optimizer, device
        )

        # Validation
        val_loss, val_acc, _, _, _ = validate(model, val_loader, criterion, device)

        # Learning rate
        current_lr = optimizer.param_groups[0]['lr']

        # Scheduler step
        if scheduler:
            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
                scheduler.step(val_loss)
            else:
                scheduler.step()

        # GeÃ§miÅŸe kaydet
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)
        history['lr'].append(current_lr)

        # Epoch sÃ¼resi
        epoch_time = time.time() - epoch_start

        # YazdÄ±r
        print(f"Epoch [{epoch+1}/{num_epochs}] ({epoch_time:.1f}s)")
        print(f"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%")
        print(f"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc*100:.2f}%")
        print(f"  LR: {current_lr:.6f}")

        # En iyi model kaydet
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            patience_counter = 0

            # Model kaydet
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_acc': val_acc,
                'val_loss': val_loss,
            }, save_path)
            print(f"  âœ“ En iyi model kaydedildi! (Val Acc: {val_acc*100:.2f}%)")
        else:
            patience_counter += 1
            print(f"  âš  Ä°yileÅŸme yok ({patience_counter}/{early_stopping_patience})")

        print()

        # Early stopping
        if patience_counter >= early_stopping_patience:
            print(f"â›” Early stopping! {early_stopping_patience} epoch boyunca iyileÅŸme olmadÄ±.")
            break

    total_time = time.time() - start_time

    print("="*60)
    print("âœ… EÄžÄ°TÄ°M TAMAMLANDI")
    print(f"Toplam sÃ¼re: {total_time/60:.2f} dakika")
    print(f"En iyi Validation Accuracy: {best_val_acc*100:.2f}%")
    print("="*60 + "\n")

    return history


# ==================== DEÄžERLENDÄ°RME METRÄ°KLERÄ° ====================
def evaluate_model(model, test_loader, device, class_names):
    """
    Model performansÄ±nÄ± detaylÄ± deÄŸerlendirir.

    Args:
        model: DeÄŸerlendirilecek model
        test_loader: Test DataLoader
        device: Cihaz
        class_names: SÄ±nÄ±f isimleri listesi

    Returns:
        dict: TÃ¼m metrikler
    """
    criterion = nn.CrossEntropyLoss()

    test_loss, test_acc, preds, labels, probs = validate(
        model, test_loader, criterion, device
    )

    # Classification Report
    report = classification_report(labels, preds, target_names=class_names, output_dict=True)
    report_text = classification_report(labels, preds, target_names=class_names)

    # Precision, Recall, F1
    precision, recall, f1, support = precision_recall_fscore_support(
        labels, preds, average=None
    )

    # Macro & Weighted averages
    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(
        labels, preds, average='macro'
    )
    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(
        labels, preds, average='weighted'
    )

    metrics = {
        'test_loss': test_loss,
        'test_accuracy': test_acc,
        'predictions': preds,
        'true_labels': labels,
        'probabilities': probs,
        'classification_report': report,
        'classification_report_text': report_text,
        'precision_per_class': precision,
        'recall_per_class': recall,
        'f1_per_class': f1,
        'support_per_class': support,
        'precision_macro': precision_macro,
        'recall_macro': recall_macro,
        'f1_macro': f1_macro,
        'precision_weighted': precision_weighted,
        'recall_weighted': recall_weighted,
        'f1_weighted': f1_weighted,
    }

    # SonuÃ§larÄ± yazdÄ±r
    print("\n" + "="*60)
    print("ðŸ“Š TEST SONUÃ‡LARI")
    print("="*60)
    print(f"Test Loss: {test_loss:.4f}")
    print(f"Test Accuracy: {test_acc*100:.2f}%")
    print(f"\nF1-Score (Macro): {f1_macro:.4f}")
    print(f"F1-Score (Weighted): {f1_weighted:.4f}")
    print(f"Precision (Macro): {precision_macro:.4f}")
    print(f"Recall (Macro): {recall_macro:.4f}")
    print("\n" + "-"*60)
    print("SINIF BAZLI RAPOR:")
    print("-"*60)
    print(report_text)
    print("="*60 + "\n")

    return metrics


# ==================== GÃ–RSELLEÅžTÄ°RME FONKSÄ°YONLARI ====================
def plot_training_history(history, save_path=None):
    """
    EÄŸitim geÃ§miÅŸini gÃ¶rselleÅŸtirir.

    Args:
        history: EÄŸitim geÃ§miÅŸi dict
        save_path: KayÄ±t yolu (opsiyonel)
    """
    fig, axes = plt.subplots(1, 3, figsize=(15, 4))

    epochs = range(1, len(history['train_loss']) + 1)

    # Loss grafiÄŸi
    axes[0].plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)
    axes[0].plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Loss')
    axes[0].set_title('Training & Validation Loss')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    # Accuracy grafiÄŸi
    axes[1].plot(epochs, [a*100 for a in history['train_acc']], 'b-', label='Train Acc', linewidth=2)
    axes[1].plot(epochs, [a*100 for a in history['val_acc']], 'r-', label='Val Acc', linewidth=2)
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Accuracy (%)')
    axes[1].set_title('Training & Validation Accuracy')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)

    # Learning Rate grafiÄŸi
    axes[2].plot(epochs, history['lr'], 'g-', linewidth=2)
    axes[2].set_xlabel('Epoch')
    axes[2].set_ylabel('Learning Rate')
    axes[2].set_title('Learning Rate Schedule')
    axes[2].grid(True, alpha=0.3)

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ EÄŸitim grafikleri kaydedildi: {save_path}")

    plt.show()


def plot_confusion_matrix(y_true, y_pred, class_names, save_path=None, normalize=True):
    """
    Confusion matrix Ä±sÄ± haritasÄ± Ã§izer.

    Args:
        y_true: GerÃ§ek etiketler
        y_pred: Tahmin edilen etiketler
        class_names: SÄ±nÄ±f isimleri
        save_path: KayÄ±t yolu (opsiyonel)
        normalize: Normalize et (yÃ¼zde olarak)
    """
    cm = confusion_matrix(y_true, y_pred)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        fmt = '.2f'
        title = 'Normalized Confusion Matrix'
    else:
        fmt = 'd'
        title = 'Confusion Matrix'

    plt.figure(figsize=(12, 10))
    sns.heatmap(
        cm,
        annot=True,
        fmt=fmt,
        cmap='Blues',
        xticklabels=class_names,
        yticklabels=class_names,
        square=True,
        linewidths=0.5
    )
    plt.xlabel('Predicted Label', fontsize=12)
    plt.ylabel('True Label', fontsize=12)
    plt.title(title, fontsize=14)
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ Confusion matrix kaydedildi: {save_path}")

    plt.show()


def plot_class_performance(metrics, class_names, save_path=None):
    """
    SÄ±nÄ±f bazlÄ± performans grafiÄŸi Ã§izer.

    Args:
        metrics: evaluate_model'den dÃ¶nen metrikler
        class_names: SÄ±nÄ±f isimleri
        save_path: KayÄ±t yolu (opsiyonel)
    """
    x = np.arange(len(class_names))
    width = 0.25

    fig, ax = plt.subplots(figsize=(14, 6))

    bars1 = ax.bar(x - width, metrics['precision_per_class'], width, label='Precision', color='#2ecc71')
    bars2 = ax.bar(x, metrics['recall_per_class'], width, label='Recall', color='#3498db')
    bars3 = ax.bar(x + width, metrics['f1_per_class'], width, label='F1-Score', color='#e74c3c')

    ax.set_xlabel('SÄ±nÄ±flar', fontsize=12)
    ax.set_ylabel('Skor', fontsize=12)
    ax.set_title('SÄ±nÄ±f BazlÄ± Performans Metrikleri', fontsize=14)
    ax.set_xticks(x)
    ax.set_xticklabels(class_names, rotation=45, ha='right')
    ax.legend()
    ax.set_ylim(0, 1.1)
    ax.grid(True, axis='y', alpha=0.3)

    # DeÄŸerleri bar Ã¼zerine yaz
    for bars in [bars1, bars2, bars3]:
        for bar in bars:
            height = bar.get_height()
            ax.annotate(f'{height:.2f}',
                       xy=(bar.get_x() + bar.get_width() / 2, height),
                       xytext=(0, 3),
                       textcoords="offset points",
                       ha='center', va='bottom', fontsize=7)

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ SÄ±nÄ±f performans grafiÄŸi kaydedildi: {save_path}")

    plt.show()


def plot_sample_predictions(model, dataloader, class_names, device, num_samples=16, save_path=None):
    """
    Ã–rnek tahminleri gÃ¶rselleÅŸtirir.

    Args:
        model: Model
        dataloader: DataLoader
        class_names: SÄ±nÄ±f isimleri
        device: Cihaz
        num_samples: GÃ¶sterilecek Ã¶rnek sayÄ±sÄ±
        save_path: KayÄ±t yolu (opsiyonel)
    """
    model.eval()

    # Bir batch al
    images, labels = next(iter(dataloader))
    images, labels = images[:num_samples].to(device), labels[:num_samples]

    with torch.no_grad():
        outputs = model(images)
        probs = torch.softmax(outputs, dim=1)
        preds = torch.argmax(probs, dim=1)
        confidences = probs.max(dim=1).values

    # Denormalize
    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
    images_denorm = images.cpu() * std + mean
    images_denorm = torch.clamp(images_denorm, 0, 1)

    # Plot
    cols = 4
    rows = (num_samples + cols - 1) // cols
    fig, axes = plt.subplots(rows, cols, figsize=(16, 4*rows))
    axes = axes.flatten()

    for i in range(num_samples):
        ax = axes[i]
        img = images_denorm[i].permute(1, 2, 0).numpy()
        ax.imshow(img)

        true_label = class_names[labels[i]]
        pred_label = class_names[preds[i].cpu()]
        conf = confidences[i].cpu().item() * 100

        color = 'green' if preds[i].cpu() == labels[i] else 'red'
        ax.set_title(f'True: {true_label}\nPred: {pred_label} ({conf:.1f}%)',
                    color=color, fontsize=10)
        ax.axis('off')

    # BoÅŸ subplot'larÄ± kapat
    for i in range(num_samples, len(axes)):
        axes[i].axis('off')

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ Ã–rnek tahminler kaydedildi: {save_path}")

    plt.show()


# ==================== MODEL KARÅžILAÅžTIRMA ====================
def compare_models(results_dict, save_path=None):
    """
    Birden fazla modelin sonuÃ§larÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±r.

    Args:
        results_dict: {model_name: metrics} formatÄ±nda sonuÃ§lar
        save_path: KayÄ±t yolu (opsiyonel)
    """
    models = list(results_dict.keys())
    metrics_to_compare = ['test_accuracy', 'f1_macro', 'precision_macro', 'recall_macro']

    # Tablo verisi hazÄ±rla
    data = []
    for model_name in models:
        row = [model_name]
        for metric in metrics_to_compare:
            value = results_dict[model_name].get(metric, 0)
            row.append(f"{value*100:.2f}%" if metric == 'test_accuracy' else f"{value:.4f}")
        data.append(row)

    # DataFrame benzeri yazdÄ±rma
    print("\n" + "="*80)
    print("ðŸ“Š MODEL KARÅžILAÅžTIRMA TABLOSU")
    print("="*80)
    headers = ['Model', 'Test Accuracy', 'F1 (Macro)', 'Precision', 'Recall']
    print(f"{headers[0]:<25} {headers[1]:<15} {headers[2]:<12} {headers[3]:<12} {headers[4]:<12}")
    print("-"*80)
    for row in data:
        print(f"{row[0]:<25} {row[1]:<15} {row[2]:<12} {row[3]:<12} {row[4]:<12}")
    print("="*80 + "\n")

    # Bar chart
    fig, axes = plt.subplots(1, 4, figsize=(16, 4))

    metric_names = ['Test Accuracy', 'F1-Score (Macro)', 'Precision (Macro)', 'Recall (Macro)']
    colors = ['#3498db', '#2ecc71', '#e74c3c', '#9b59b6']

    for i, (metric, metric_name) in enumerate(zip(metrics_to_compare, metric_names)):
        values = [results_dict[m][metric] * 100 for m in models]
        bars = axes[i].bar(models, values, color=colors[i], alpha=0.8)
        axes[i].set_title(metric_name)
        axes[i].set_ylabel('DeÄŸer (%)')
        axes[i].set_ylim(0, 105)
        axes[i].tick_params(axis='x', rotation=15)

        # DeÄŸerleri bar Ã¼zerine yaz
        for bar, val in zip(bars, values):
            axes[i].annotate(f'{val:.1f}%',
                           xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),
                           xytext=(0, 3),
                           textcoords="offset points",
                           ha='center', va='bottom', fontsize=10)

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ Model karÅŸÄ±laÅŸtÄ±rma grafiÄŸi kaydedildi: {save_path}")

    plt.show()


# ==================== MODEL KAYDETME/YÃœKLEME ====================
def save_checkpoint(model, optimizer, epoch, val_acc, path):
    """Model checkpoint kaydeder"""
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'val_acc': val_acc,
    }, path)
    print(f"âœ“ Checkpoint kaydedildi: {path}")


def load_checkpoint(model, path, optimizer=None):
    """Model checkpoint yÃ¼kler"""
    checkpoint = torch.load(path)
    model.load_state_dict(checkpoint['model_state_dict'])

    if optimizer:
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

    print(f"âœ“ Checkpoint yÃ¼klendi: {path}")
    print(f"  Epoch: {checkpoint['epoch']}, Val Acc: {checkpoint['val_acc']*100:.2f}%")

    return checkpoint


# ==================== TEST ====================
if __name__ == "__main__":
    print("Train Utils Test")
    print("-" * 40)

    # Dummy test
    history = {
        'train_loss': [0.8, 0.5, 0.3, 0.2, 0.15],
        'train_acc': [0.6, 0.75, 0.85, 0.9, 0.93],
        'val_loss': [0.7, 0.45, 0.35, 0.28, 0.25],
        'val_acc': [0.65, 0.78, 0.82, 0.88, 0.90],
        'lr': [0.001, 0.001, 0.0005, 0.0005, 0.00025]
    }

    print("Plotting training history...")
    plot_training_history(history)

